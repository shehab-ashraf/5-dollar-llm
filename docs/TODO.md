# üìù Project TODOs

- [ ] Train on 1B tokens 2 times (with an initial warmup on 8M tokens) and record as baseline in [LEADERBOARD.md](LEADERBOARD.md).
- [ ] Train on 100M tokens just once using the `bf16-optimization-100m` setup.

git checkout -b bf16-experiment bf16-optimization-100m

